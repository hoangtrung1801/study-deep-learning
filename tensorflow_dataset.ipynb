{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpz1I7ZxcYPvIgfvAQOjDB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangtrung1801/study-deep-learning/blob/main/tensorflow_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlyoeR5NxMU2",
        "outputId": "43fc5a3f-4fad-4c66-ac3e-e3578faa1e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting remotezip\n",
            "  Downloading remotezip-0.12.1.tar.gz (7.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from remotezip) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from remotezip) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.4)\n",
            "Building wheels for collected packages: remotezip\n",
            "  Building wheel for remotezip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for remotezip: filename=remotezip-0.12.1-py3-none-any.whl size=7933 sha256=c92a20d5f8b1720913b3e89899f2a7424b912c1c1671293bfd57e4667ceb4c30\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/76/04/beed1a6df4eb7430ee13c3900746edd517e5e597298d1f73f3\n",
            "Successfully built remotezip\n",
            "Installing collected packages: remotezip\n",
            "Successfully installed remotezip-0.12.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install remotezip tqdm opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import remotezip as rz\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "from tensorflow_docs.vis import embed"
      ],
      "metadata": {
        "id": "_Ar0rbET54YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'"
      ],
      "metadata": {
        "id": "4H-Hx8hG59lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files_from_zip_url(zip_url):\n",
        "  \"\"\" List the files in each class of the dataset given a URL with the zip file.\n",
        "\n",
        "    Args:\n",
        "      zip_url: A URL from which the files can be extracted from.\n",
        "\n",
        "    Returns:\n",
        "      List of files in each of the classes.\n",
        "  \"\"\"\n",
        "  files = []\n",
        "  with rz.RemoteZip(zip_url) as zip:\n",
        "    for zip_info in zip.infolist():\n",
        "      files.append(zip_info.filename)\n",
        "  return files"
      ],
      "metadata": {
        "id": "yZrO5V236Erv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = list_files_from_zip_url(URL)\n",
        "files = [f for f in files if f.endswith('.avi')]\n",
        "files[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWq042nd6GzQ",
        "outputId": "5cf5c1d7-e2e2-4e83-b5ba-bffc9c4a2dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['UCF101/v_ApplyEyeMakeup_g01_c01.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g01_c02.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g01_c03.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g01_c04.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g01_c05.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g01_c06.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g02_c01.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g02_c02.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g02_c03.avi',\n",
              " 'UCF101/v_ApplyEyeMakeup_g02_c04.avi']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(fname):\n",
        "  return fname.split('_')[-3]"
      ],
      "metadata": {
        "id": "CeqPceha6vS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files_per_class(files):\n",
        "  \"\"\" Retrieve the files that belong to each class.\n",
        "\n",
        "    Args:\n",
        "      files: List of files in the dataset.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary of class names (key) and files (values).\n",
        "  \"\"\"\n",
        "  files_for_class = collections.defaultdict(list)\n",
        "  for fname in files:\n",
        "    class_name = get_class(fname)\n",
        "    files_for_class[class_name].append(fname)\n",
        "  return files_for_class"
      ],
      "metadata": {
        "id": "N3PsfIeB66lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "FILES_PER_CLASS = 50"
      ],
      "metadata": {
        "id": "jdu5MtT97U3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_for_class = get_files_per_class(files)\n",
        "classes = list(files_for_class.keys())"
      ],
      "metadata": {
        "id": "OyjtZbFy7WWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
        "  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n",
        "\n",
        "    Args:\n",
        "      files_for_class: Dictionary of class names (key) and files (values).\n",
        "      classes: List of classes.\n",
        "      files_per_class: Number of files per class of interest.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary with class as key and list of specified number of video files in that class.\n",
        "  \"\"\"\n",
        "  files_subset = dict()\n",
        "\n",
        "  for class_name in classes:\n",
        "    class_files = files_for_class[class_name]\n",
        "    files_subset[class_name] = class_files[:files_per_class]\n",
        "\n",
        "  return files_subset\n",
        "\n",
        "files_subset = select_subset_of_classes(files_for_class, classes[:NUM_CLASSES], FILES_PER_CLASS)"
      ],
      "metadata": {
        "id": "fT6DxA0p7eY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_from_zip(zip_url, to_dir, file_names):\n",
        "  \"\"\" Download the contents of the zip file from the zip URL.\n",
        "\n",
        "    Args:\n",
        "      zip_url: A URL with a zip file containing data.\n",
        "      to_dir: A directory to download data to.\n",
        "      file_names: Names of files to download.\n",
        "  \"\"\"\n",
        "  with rz.RemoteZip(zip_url) as zip:\n",
        "    for fn in tqdm.tqdm(file_names):\n",
        "      class_name = get_class(fn)\n",
        "      zip.extract(fn, str(to_dir / class_name))\n",
        "      unzipped_file = to_dir / class_name / fn\n",
        "\n",
        "      fn = pathlib.Path(fn).parts[-1]\n",
        "      output_file = to_dir / class_name / fn\n",
        "      unzipped_file.rename(output_file)\n",
        "\n",
        "def split_class_lists(files_for_class, count):\n",
        "  \"\"\" Returns the list of files belonging to a subset of data as well as the remainder of\n",
        "    files that need to be downloaded.\n",
        "\n",
        "    Args:\n",
        "      files_for_class: Files belonging to a particular class of data.\n",
        "      count: Number of files to download.\n",
        "\n",
        "    Returns:\n",
        "      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n",
        "  \"\"\"\n",
        "  split_files = []\n",
        "  remainder = {}\n",
        "  for cls in files_for_class:\n",
        "    split_files.extend(files_for_class[cls][:count])\n",
        "    remainder[cls] = files_for_class[cls][count:]\n",
        "  return split_files, remainder\n",
        "\n",
        "def download_ucf_101_subset(zip_url, num_classes, splits, download_dir):\n",
        "  \"\"\" Download a subset of the UCF101 dataset and split them into various parts, such as\n",
        "    training, validation, and test.\n",
        "\n",
        "    Args:\n",
        "      zip_url: A URL with a ZIP file with the data.\n",
        "      num_classes: Number of labels.\n",
        "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data\n",
        "              (value is number of files per split).\n",
        "      download_dir: Directory to download data to.\n",
        "\n",
        "    Return:\n",
        "      Mapping of the directories containing the subsections of data.\n",
        "  \"\"\"\n",
        "  files = list_files_from_zip_url(zip_url)\n",
        "  for f in files:\n",
        "    path = os.path.normpath(f)\n",
        "    tokens = path.split(os.sep)\n",
        "    if len(tokens) <= 2:\n",
        "      files.remove(f) # Remove that item from the list if it does not have a filename\n",
        "\n",
        "  files_for_class = get_files_per_class(files)\n",
        "\n",
        "  classes = list(files_for_class.keys())[:num_classes]\n",
        "\n",
        "  for cls in classes:\n",
        "    random.shuffle(files_for_class[cls])\n",
        "\n",
        "  # Only use the number of classes you want in the dictionary\n",
        "  files_for_class = {x: files_for_class[x] for x in classes}\n",
        "\n",
        "  dirs = {}\n",
        "  for split_name, split_count in splits.items():\n",
        "    print(split_name, \":\")\n",
        "    split_dir = download_dir / split_name\n",
        "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
        "    download_from_zip(zip_url, split_dir, split_files)\n",
        "    dirs[split_name] = split_dir\n",
        "\n",
        "  return dirs"
      ],
      "metadata": {
        "id": "Atxx3Mqg8gRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_dir = pathlib.Path('./UCF101_subset/')\n",
        "subset_paths = download_ucf_101_subset(URL,\n",
        "                                       num_classes = NUM_CLASSES,\n",
        "                                       splits = {\"train\": 30, \"val\": 10, \"test\": 10},\n",
        "                                       download_dir = download_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJK4TuIf9fll",
        "outputId": "964df61e-1bb3-41fb-f946-571038258212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:36<00:00,  8.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:12<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.23it/s]\n"
          ]
        }
      ]
    }
  ]
}